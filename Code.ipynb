{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.classification import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'train/neg/'\n",
    "neg = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentlist = []\n",
    "\n",
    "for negative in neg:\n",
    "    with open('train/neg/{}'.format(negative), 'r', encoding=\"utf8\") as f1:\n",
    "        documentlist.append([f1.read(), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'train/pos/'\n",
    "pos = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for positive in pos:\n",
    "    with open('train/pos/{}'.format(positive), 'r', encoding=\"utf8\") as f1:\n",
    "        documentlist.append([f1.read(), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content  Feedback\n",
       "24995  Seeing as the vote average was pretty low, and...         1\n",
       "24996  The plot had some wretched, unbelievable twist...         1\n",
       "24997  I am amazed at how this movie(and most others ...         1\n",
       "24998  A Christmas Together actually came before my t...         1\n",
       "24999  Working-class romantic drama from director Mar...         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentDF = pd.DataFrame(documentlist, columns = ['Content', 'Feedback'])\n",
    "documentDF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentDF.to_csv('traindata.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentlist = []\n",
    "\n",
    "path = 'test/neg/'\n",
    "neg = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for negative in neg:\n",
    "    with open('test/neg/{}'.format(negative), 'r', encoding=\"utf8\") as f1:\n",
    "        documentlist.append([f1.read(), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test/pos/'\n",
    "pos = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for positive in pos:\n",
    "    with open('test/pos/{}'.format(positive), 'r', encoding=\"utf8\") as f1:\n",
    "        documentlist.append([f1.read(), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I was extraordinarily impressed by this film. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Although I'm not a golf fan, I attended a snea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>From the start of \"The Edge Of Love\", the view...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>This movie, with all its complexity and subtle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I've seen this story before but my kids haven'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content  Feedback\n",
       "24995  I was extraordinarily impressed by this film. ...         1\n",
       "24996  Although I'm not a golf fan, I attended a snea...         1\n",
       "24997  From the start of \"The Edge Of Love\", the view...         1\n",
       "24998  This movie, with all its complexity and subtle...         1\n",
       "24999  I've seen this story before but my kids haven'...         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentDF = pd.DataFrame(documentlist, columns = ['Content', 'Feedback'])\n",
    "documentDF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentDF.to_csv('testdata.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content  Feedback\n",
      "0  Story of a man who has unnatural feelings for ...         0\n",
      "1  Airport '77 starts as a brand new luxury 747 p...         0\n",
      "2  This film lacked something I couldn't put my f...         0\n",
      "3  Sorry everyone,,, I know this is supposed to b...         0\n",
      "4  When I was little my parents took me along to ...         0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('traindata.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# declare empty list 'corpus'\n",
    "corpus = []\n",
    "\n",
    "# for loop to fill in corpus\n",
    "for i in range(0, 25000):\n",
    "    review = df['Content'].iloc[i]\n",
    "    # retain alphabets\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    # convert to lower case\n",
    "    review = review.lower()\n",
    "    # tokenize\n",
    "    review = review.split()\n",
    "    # initialize stemmer object\n",
    "    ps = PorterStemmer()\n",
    "    # perform stemming\n",
    "    review = [word for word in review if word not in stopwords.words('english')]\n",
    "    review = [ps.stem(i) for i in review]\n",
    "    # join elements of list\n",
    "    review = ' '.join(review)\n",
    "    # add to 'corpus'\n",
    "    corpus.append(review)\n",
    "    \n",
    "# display 'corpus'\n",
    "print(corpus)\n",
    "\n",
    "print('Corpus created! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate count vectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "\n",
    "# Independent variable\n",
    "X_train = cv.fit_transform(corpus)\n",
    "\n",
    "# dependent variable\n",
    "y_train = df['Feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content  Feedback\n",
      "0  Once again Mr. Costner has dragged out a movie...         0\n",
      "1  This is an example of why the majority of acti...         0\n",
      "2  First of all I hate those moronic rappers, who...         0\n",
      "3  Not even the Beatles could write songs everyon...         0\n",
      "4  Brass pictures (movies is not a fitting word f...         0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df1 = pd.read_csv('testdata.csv')\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "corpus_test = []\n",
    "\n",
    "# for loop to fill in corpus\n",
    "for i in range(0, 25000):\n",
    "    review = df1['Content'].iloc[i]\n",
    "    # retain alphabets\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    # convert to lower case\n",
    "    review = review.lower()\n",
    "    # tokenize\n",
    "    review = review.split()\n",
    "    # initialize stemmer object\n",
    "    ps = PorterStemmer()\n",
    "    # perform stemming\n",
    "    review = [word for word in review if word not in stopwords.words('english')]\n",
    "    review = [ps.stem(i) for i in review]\n",
    "    # join elements of list\n",
    "    review = ' '.join(review)\n",
    "    # add to 'corpus'\n",
    "    corpus_test.append(review)\n",
    "    \n",
    "# display 'corpus'\n",
    "print(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus created! Time elapsed: 1121.0855565071106 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Corpus created! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variable\n",
    "X_test = cv.fit_transform(corpus_test)\n",
    "\n",
    "# dependent variable\n",
    "y_test = df1['Feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insatntiate calssifier\n",
    "rf = RandomForestClassifier(random_state=2)\n",
    "\n",
    "# fit modelk on training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5026\n",
      "Precision:  0.5043\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# calculate the precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# display 'score' and 'precision'\n",
    "print(\"Score: \", round(score, 4))\n",
    "print(\"Precision: \", round(precision, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with XGBOOSTING:  0.50384\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(base_estimator=rf, random_state=0)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "xgb_score = xgb_clf.score(X_test, y_test)\n",
    "print(\"Score with XGBOOSTING: \", xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5038\n",
      "Precision:  0.5034\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# calculate the precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# display 'score' and 'precision'\n",
    "print(\"Score: \", round(score, 4))\n",
    "print(\"Precision: \", round(precision, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76     12500\n",
      "           1       0.80      0.62      0.70     12500\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     25000\n",
      "   macro avg       0.75      0.73      0.73     25000\n",
      "weighted avg       0.75      0.73      0.73     25000\n",
      "\n",
      "ACCURACY:: 0.73368\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# generate your cross-validation prediction with 10 fold Stratified sampling\n",
    "y_pred = cross_val_predict(nb, X_train.toarray(), y_test, cv=10)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY::\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=100,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<bound method TreebankWordTokenizer.tokenize of <nltk.tokenize.treebank.TreebankWordTokenizer object at 0x000000007053D6A0>>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "#instantiate TfidfVectorizer (with the default parameters)\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "vect.set_params(tokenizer=tokenizer.tokenize)\n",
    "\n",
    "# remove English stop words\n",
    "vect.set_params(stop_words='english')\n",
    "\n",
    "# include 1-grams and 2-grams\n",
    "vect.set_params(ngram_range=(1, 3))\n",
    "\n",
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect.set_params(max_df=0.5)\n",
    "\n",
    "# only keep terms that appear in at least 2 documents\n",
    "vect.set_params(min_df=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = vect.fit_transform(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(train_vectors.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = vect.transform(df1['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82     12500\n",
      "           1       0.82      0.81      0.82     12500\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     25000\n",
      "   macro avg       0.82      0.82      0.82     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n",
      "ACCURACY:: 0.8174\n"
     ]
    }
   ],
   "source": [
    "# generate your cross-validation prediction with 10 fold Stratified sampling\n",
    "y_pred = cross_val_predict(nb, test_vectors.toarray(), y_test, cv=10)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print (\"ACCURACY::\",accuracy_score(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
